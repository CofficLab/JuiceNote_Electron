# 性能

## 性能指标

### 测试代码

运行如下测试性能的代码：

<div class="run"></div>

```sh
ab -n 100 -c 1 'http://127.0.0.1:8000/'
```

### 响应时间

指的是某个请求从发出到接收到响应所消耗的时间。

在对响应时间进行测试时，通常采用重复请求的方式，然后计算平均响应时间。

当前，我们仅有一台服务器，应用程序、数据库、文件存储都在这台服务器上。

此时，通过测试，应用程序的平均响应时间是：

```
Time per request:       0.499 [ms] (mean)
```

非常快，目前程序运行良好。

### 吞吐量

指系统在单位时间内可以处理的请求数量，通常使用每秒的请求数来衡量。

此时，通过测试，应用程序的吞吐量是：

```
Requests per second:    3482.02 [#/sec] (mean)
```

每秒能够处理 `3482.02` 个请求，非常棒。

### 并发用户数

指系统能同时处理的并发用户请求数量。

在没有并发存在的系统中，请求被顺序执行，此时响应时间为吞吐量的倒数。

例如：

系统的吞吐量为 100 req/s，那么平均响应时间应该为 0.01s。

目前的大型系统都支持多线程来处理并发请求，多线程能够提高吞吐量以及缩短响应时间，主要有两个原因：

- 多 CPU
- IO 等待时间

使用 IO 多路复用等方式，系统在等待一个 IO 操作完成的这段时间内不需要被阻塞，可以去处理其他请求。

通过将这个等待时间利用起来，使得 CPU 利用率大大提高。

并发用户数并不是越高越好，因为如果并发用户数太高，系统来不及处理这么多的请求，会使得过多的请求需要等待，那么响应时间就会大大提高。

<div class="run"></div>

```sh
ab -n 100 -c 100 'http://127.0.0.1:8000/'
```

网站业务发展顺利，用户量越来越大，我们提高并发数来模拟这一情况，可见单个请求的耗时延长了：

```
Time per request:       35.413 [ms] (mean)
```

## 性能优化

用户量越来越大，数据越来越多，我们面临两个问题：

- 用户反馈访问网站的时间越来越长了
- 数据库存储的数据越来越多，存储即将达到瓶颈

这时，一台服务器逐渐不能满足要求。我们需要想办法优化性能。

### 应用和数据分离

应用和数据分离后，整个网站使用三台服务器，且三台服务器硬件资源各有侧重：

- 应用服务器：处理大量的业务逻辑，需要更快更强的 CPU
- 文件服务器：存储大量文件，需要更大的磁盘
- 数据库服务器：存储和查询数据，需要更快的磁盘和更大的内存

### 缓存

分析数据库面临压力的原因：

- 大量的用户访问某些热门商品
- 不断从数据库查询这些热门商品的详情

内存的读写速度要比磁盘快得多，我们可以把这些热门商品的数据存储到内存中以加快访问速度，降低磁盘压力。

网站使用的缓存可以分为两种：

- 缓存在应用服务器上的本地缓存
- 缓存在专门的分布式缓存服务器上的远程缓存

本地缓存的访问速度显然更快，但受限于服务器的内存限制，缓存的数据量有限，而且可能出现和应用程序争内存的情况。

远程分布式缓存可以使用集群的方式，部署大内存的服务器作为专门的缓存服务器。

因为使用集群，理论上可以无限添加内存，使得缓存数据量不受限制。

缓存能够提高性能的原因如下：

- 缓存数据通常位于内存等介质中，这种介质对于读操作特别快；
- 缓存数据可以位于靠近用户的地理位置上；
- 将计算结果进行缓存，从而避免重复计算。

### 集群

但又有了新的挑战：访问高峰期，应用服务器的硬件资源告急，CPU 使用率常常达到 90% 以上

一个很直接的想法是：换一个性能更强的服务器。

但是，业务量的增长是无限的，单台服务器的性能始终是有限的，而且更换服务器还会造成服务中断。

使用集群是解决网站高并发、海量数据处理问题的常用手段。

将多台服务器组成集群，使用负载均衡将请求转发到集群中，避免单一服务器的负载压力过大导致性能降低。

应用服务器再次遇到压力时，还可以继续增加服务器来改善，压力降低，有服务器闲置时，可以下线一台或多台服务器，从而实现**可伸缩性**。

### 异步

某些流程可以将操作转换为消息，将消息发送到消息队列后立即返回，之后这个操作会被异步处理。
